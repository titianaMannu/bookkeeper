<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="it"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>EntryLogCompactor.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">Tests</a> &gt; <a href="../index.html" class="el_bundle">bookkeeper-server</a> &gt; <a href="index.source.html" class="el_package">org.apache.bookkeeper.bookie</a> &gt; <span class="el_source">EntryLogCompactor.java</span></div><h1>EntryLogCompactor.java</h1><pre class="source lang-java linenums">/**
 *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 *
 */

package org.apache.bookkeeper.bookie;

import io.netty.buffer.ByteBuf;

import java.io.IOException;
import java.util.ArrayList;
import java.util.List;

import org.apache.bookkeeper.conf.ServerConfiguration;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * This is the basic entry log compactor to compact entry logs.
 * The compaction is done by scanning the old entry log file, copy the active ledgers to the
 * current entry logger and remove the old entry log when the scan is over.
 */
public class EntryLogCompactor extends AbstractLogCompactor {
<span class="fc" id="L40">    private static final Logger LOG = LoggerFactory.getLogger(EntryLogCompactor.class);</span>

<span class="fc" id="L42">    final CompactionScannerFactory scannerFactory = new CompactionScannerFactory();</span>
    final EntryLogger entryLogger;
    final CompactableLedgerStorage ledgerStorage;
    private final int maxOutstandingRequests;

    public EntryLogCompactor(
            ServerConfiguration conf,
            EntryLogger entryLogger,
            CompactableLedgerStorage ledgerStorage,
            LogRemovalListener logRemover) {
<span class="fc" id="L52">        super(conf, logRemover);</span>
<span class="fc" id="L53">        this.maxOutstandingRequests = conf.getCompactionMaxOutstandingRequests();</span>
<span class="fc" id="L54">        this.entryLogger = entryLogger;</span>
<span class="fc" id="L55">        this.ledgerStorage = ledgerStorage;</span>
<span class="fc" id="L56">    }</span>

    @Override
    public boolean compact(EntryLogMetadata entryLogMeta) {
        try {
<span class="nc" id="L61">            entryLogger.scanEntryLog(entryLogMeta.getEntryLogId(),</span>
<span class="nc" id="L62">                scannerFactory.newScanner(entryLogMeta));</span>
<span class="nc" id="L63">            scannerFactory.flush();</span>
<span class="nc" id="L64">            LOG.info(&quot;Removing entry log {} after compaction&quot;, entryLogMeta.getEntryLogId());</span>
<span class="nc" id="L65">            logRemovalListener.removeEntryLog(entryLogMeta.getEntryLogId());</span>
<span class="nc" id="L66">        } catch (LedgerDirsManager.NoWritableLedgerDirException nwlde) {</span>
<span class="nc" id="L67">            LOG.warn(&quot;No writable ledger directory available, aborting compaction&quot;, nwlde);</span>
<span class="nc" id="L68">            return false;</span>
<span class="nc" id="L69">        } catch (IOException ioe) {</span>
            // if compact entry log throws IOException, we don't want to remove that
            // entry log. however, if some entries from that log have been re-added
            // to the entry log, and the offset updated, it's ok to flush that
<span class="nc" id="L73">            LOG.error(&quot;Error compacting entry log. Log won't be deleted&quot;, ioe);</span>
<span class="nc" id="L74">            return false;</span>
<span class="nc" id="L75">        }</span>
<span class="nc" id="L76">        return true;</span>
    }

    /**
     * A scanner wrapper to check whether a ledger is alive in an entry log file.
     */
<span class="fc" id="L82">    class CompactionScannerFactory {</span>
<span class="fc" id="L83">        List&lt;EntryLocation&gt; offsets = new ArrayList&lt;EntryLocation&gt;();</span>

        EntryLogger.EntryLogScanner newScanner(final EntryLogMetadata meta) {

<span class="nc" id="L87">            return new EntryLogger.EntryLogScanner() {</span>
                @Override
                public boolean accept(long ledgerId) {
<span class="nc" id="L90">                    return meta.containsLedger(ledgerId);</span>
                }

                @Override
                public void process(final long ledgerId, long offset, ByteBuf entry) throws IOException {
<span class="nc" id="L95">                    throttler.acquire(entry.readableBytes());</span>

<span class="nc bnc" id="L97" title="All 2 branches missed.">                    if (offsets.size() &gt; maxOutstandingRequests) {</span>
<span class="nc" id="L98">                        flush();</span>
                    }
<span class="nc" id="L100">                    long entryId = entry.getLong(entry.readerIndex() + 8);</span>

<span class="nc" id="L102">                    long newoffset = entryLogger.addEntry(ledgerId, entry);</span>
<span class="nc" id="L103">                    offsets.add(new EntryLocation(ledgerId, entryId, newoffset));</span>

<span class="nc" id="L105">                }</span>
            };
        }

        void flush() throws IOException {
<span class="nc bnc" id="L110" title="All 2 branches missed.">            if (offsets.isEmpty()) {</span>
<span class="nc bnc" id="L111" title="All 2 branches missed.">                if (LOG.isDebugEnabled()) {</span>
<span class="nc" id="L112">                    LOG.debug(&quot;Skipping entry log flushing, as there are no offset!&quot;);</span>
                }
<span class="nc" id="L114">                return;</span>
            }

            // Before updating the index, we want to wait until all the compacted entries are flushed into the
            // entryLog
            try {
<span class="nc" id="L120">                entryLogger.flush();</span>
<span class="nc" id="L121">                ledgerStorage.updateEntriesLocations(offsets);</span>
<span class="nc" id="L122">                ledgerStorage.flushEntriesLocationsIndex();</span>
            } finally {
<span class="nc" id="L124">                offsets.clear();</span>
            }
<span class="nc" id="L126">        }</span>
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.4.201905082037</span></div></body></html>